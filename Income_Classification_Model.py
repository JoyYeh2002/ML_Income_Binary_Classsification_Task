# -*- coding: utf-8 -*-
"""
Created on Wed Jan 13 23:10:50 2021
Logistic Regression Model for Predicting Annual Income
EN.580.140 Statistical Foundations in ML

"""

# Open and load the data using numpy arrays.
import numpy as np
import os

np.random.seed(0)

pwd = os.getcwd()
x_train_fpath = pwd + '/data/X_train.txt'
y_train_fpath = pwd + '/data/Y_train.txt'
x_test_fpath  = pwd + '/data/X_test.txt'

# The first rows of the documents are the names of the features, so the usable data starts from
# the second line. Split up each vector.

with open(x_train_fpath) as f:
    next(f)
    x_train = np.array([line.strip('\n').split(',')[1:] for line in f], dtype = float)
with open(y_train_fpath) as f:
    next(f)
    y_train = np.array([line.strip('\n').split(',')[1] for line in f], dtype = float)
with open(x_test_fpath) as f:
    next(f)
    x_test = np.array([line.strip('\n').split(',')[1:] for line in f], dtype = float)
    
# Print out information about the original data
print('x_train :\n', x_train, x_train.shape,'\n')
print('y_train :\n', y_train, y_train.shape,'\n')
print('x_test :\n', x_test, x_test.shape)

# Create a normalizatoin function that calculates a subset of data, the mean, and 
# standard deviations. 
def _normalize(x, train = True, specified_column = None, x_mean = None, x_std = None):
    # If columns are not specified, calculate all the columns. Otherwise, get
    # specific columns. 
    if specified_column == None:
        specified_column = np.arange(x.shape[1])
    
    # If training data is selected, only calculate rhe mean and std of the 
    # training data. 
    if train:
        # The reshape(1, -1) transposed the np.mean output into a row vector. 
        x_mean = np.mean(x[:, specified_column], axis = 0).reshape(1, -1)
        
        # calculate the std of specified columns. 
        x_std = np.std(x[:, specified_column], axis = 0).reshape(1, -1)
    x[:, specified_column] = (x[:, specified_column] - x_mean) / (x_std + 1e-8)
    
    return x, x_mean, x_std

# Splits x_train and y_train into training and validadtion sets based on the 
# specified ratio. Then, return the split sets. 
def _train_split(x, y, validation_ratio = 0.25):
    
    train_size = int(len(x) * (1 - validation_ratio))
    
    return x[:train_size], y[:train_size], x[train_size:], y[train_size:]

# Normalize the training and testing data. Then print out the sizes.
x_train, x_mean, x_std = _normalize(x_train, train = True)
x_test, _, _ = _normalize(x_test, train = False, x_mean = x_mean, x_std = x_std)
x_training_set, y_training_set, x_validation_set, y_validation_set = _train_split(x_train, y_train, validation_ratio = 0.1)

print('x_train:', x_training_set.shape, '\n', x_training_set)
print('---------------------------------------------------------------')
print('y_train:', y_training_set.shape, '\n', y_training_set)
print('---------------------------------------------------------------')
print('x_validation:', x_validation_set.shape, '\n', x_validation_set)
print('---------------------------------------------------------------')
print('y_validation:', y_validation_set.shape, '\n', y_validation_set)
print('---------------------------------------------------------------')

# Randomly re-order elements of the training and validation sets.
def _shuffle(x, y):
    randomize = np.arrange(len(x))
    np.ramdom.shuffle(randomize)
    
    return x[randomize], y[randomize]

# Apply the sigmoid function so that the output is always between 0 and 1. This
# calculates the probablity of a specific occurance. 
# Use np.clip(a, a_min, a_max) to keep the outputs in a range so that they don't go on to -Inf or infinitely
# close to 1. 
def _sigmoid(z):
    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))

# The proposed function learned from the current iteration. x is the input, 
# w is the weight, b is the bias. 
# In a logistic regressiong, the linear function passes through the sigmoid
# np.dot(x, w) takes the dot product of each dimension of x and each dimension 
# of w, which outputs a scalar. The bias is also updated through each iteration. 
def _f(x, w, b):
    return _sigmoid(np.dot(x, w) + b)

# Do binary classification on the model result at a threshold = 0.5
def _predict(x, w, b):
    return np.round(_f(x, w, b)).astype(np.int)

# Tally the number of wrong answers. Accuracy = (1 - error rate).
def _accuracy(y_predict, y_label):
    acc = 1 - np.mean(np.abs(y_predict - y_label))
    return acc

"""
- Cross entropy loss measures the differences between the actual probabilty distribution 
and the one generated by our fundcion.
- The smaller the loss value, the better. 
- When plotting the loss vs. time graph, we also hope to see
- Derivation of this formula (notes from lectures)
- Loss(w, b) = f(x1) * f(x2) * f(1-f(3)) * f(1-f(4)) * ...
                 ^ probability of outputting 1  ^Probability of outputting 0
- The best parameters, w and b, are denoted w* and b*. 
  w*, b* = argmax(Loss(w, b), which is equivalent to:
  w*, b* = argmin(-ln(Loss(w, b)))
  Loss(w, b) = -Σ[-y_label * ln(f(xn)) + (1 - y_label) * ln(1 - f(xn))]
- np.log() is equivalent to ln(). np.dot() implicitly calculates the summation 
- over n instances of data. 
"""
def _cross_entropy_loss(y_predict, y_label):
    cross_entropy = -(np.dot(y_label, np.log(y_predict)) + np.dot((1 - y_label), np.log(1 - y_predict)))
    return cross_entropy

# From the loss function L(w,b) = -Σ(y_label*ln(y)+(1-y_label)*ln(1-y)), we 
# take the partial derivatives of w and b, respectively. 
# Gradient of w = -Σ(y_label - y) * x
# Gradient of b = -Σ(y_label - y)
def _gradient(x, y_label, w, b):
    y_predict = _f(x, w, b)
    w_gradient = -np.sum((y_label - y_predict) * x.T, 1)
    b_gradient = -np.sum(y_label - y_predict)
    
    return w_gradient, b_gradient

# Set variables for the sizes of different sets.
train_size = x_training_set.shape[0]
validation_size = x_validation_set.shape[0]
dim = x_training_set.shape[1]

# Initialize w and b.
w = np.zeros(dim)
b = np.zeros(1)

# Set the number of iterations and the initial learning rate.
max_iter = 600
learning_rate = 1

# Create empty result arrays
training_set_loss = []
training_set_acc = []
validation_set_loss = []
validation_set_acc = []

# Adagrad is a method that set custom learning rates that decrease as #iterations increase.
w_adagrad = 1e-8
b_adagrad = 1e-8

# Apply the previously-defined functions to train max_iter number of times. 
for epoch in range(max_iter):
    w_gradient, b_gradient = _gradient(x_training_set, y_training_set, w, b)
    
    w_adagrad = w_adagrad + np.power(w_gradient, 2)
    b_adagrad = b_adagrad + np.power(b_gradient, 2)
    
    w = w - learning_rate * w_gradient / np.sqrt(w_adagrad)
    b = b - learning_rate * b_gradient / np.sqrt(b_adagrad)
    
    y_training_predict = _predict(x_training_set, w, b)
    y_probability = _f(x_training_set, w, b)
    acc = _accuracy(y_training_predict, y_training_set)
    loss = _cross_entropy_loss(y_probability, y_training_set)
    training_set_acc.append(acc)
    training_set_loss.append(loss)
    print('training_acc_%d  : %f \t training_loss_%d  : %f'%(epoch, acc, epoch, loss))
    
    y_validation_predict = _predict(x_validation_set, w, b)
    y_probability = _f(x_validation_set, w, b)
    acc = _accuracy(y_validation_predict, y_validation_set)
    loss = _cross_entropy_loss(y_probability, y_validation_set)
    validation_set_acc.append(acc)
    validation_set_loss.append(loss)

# This prints the final result of the training. With 600 iterations.
print('validation_acc_%d : %f \t training_loss_%d : %f'%(epoch, acc, epoch, loss))
print()

import matplotlib.pyplot as plt

# Plot the loss vs. iteration curve
plt.plot(training_set_loss, 'b')
plt.plot(validation_set_loss, 'm')
plt.title('Iteration Number vs. Loss with %d Iterations'%(max_iter))
plt.legend(['Training Set', 'Validation Set'])

plt.xlabel('Iteration Number')
plt.ylabel('Loss Value')

plt.savefig(pwd + '\outputs\loss_Gradient.png')
plt.show()

# Plot the accuracy vs. iteration curve
plt.plot(training_set_acc, 'g')
plt.plot(validation_set_acc, 'c')
plt.title('Iteration Number vs. Accuracy with %d Iterations'%(max_iter))
plt.legend(['Training Set', 'Validation Set'])

plt.xlabel('Iteration Number')
plt.ylabel('Loss Value')

plt.savefig(pwd + '\outputs\Accuracy_Gradient.png')
plt.show()

# Now a model is trained. Use the latest w, b parameters on the x_test set
# to get all the output results.
# Then, write the .csv file of predictions. 
import csv
y_test_predict = _predict(x_test, w, b)
print(y_test_predict, y_test_predict.shape)

with open(pwd +'\outputs\Income_Prediction_Outputs.csv', mode = 'w', newline = '') as f:
    csv_writer = csv.writer(f)
    header = ['Subject ID', 'Binary Label']
    print(header)
    csv_writer.writerow(header)
    for i in range(y_test_predict.shape[0]):
        row = [str(i), y_test_predict[i]]
        csv_writer.writerow(row)
        print(row)

        